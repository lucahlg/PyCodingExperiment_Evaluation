EXECUTE
import pandas as pd

# Load the dataset
data_path = 'parkinsons_data/parkinsons.data'
df = pd.read_csv(data_path)

# Display the first few rows of the dataset
df.head()
STDOUT/STDERR
             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \
0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   
1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   
2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   
3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   
4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   

   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \
0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   
1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   
2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   
3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   
4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   

   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \
0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   
1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   
2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   
3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   
4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   

    spread2        D2       PPE  
0  0.266482  2.301442  0.284654  
1  0.335590  2.486855  0.368674  
2  0.311173  2.342259  0.332634  
3  0.334147  2.405554  0.368975  
4  0.234513  2.332180  0.410335  

[5 rows x 24 columns]
[Jupyter current working directory: /workspace]
[Jupyter Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]
EXECUTE
from sklearn.preprocessing import MinMaxScaler

# Drop the 'name' column
df = df.drop(columns=['name'])

# Check for missing values
missing_values = df.isnull().sum()

# Normalize the data using Min-Max scaling
scaler = MinMaxScaler()
df[df.columns] = scaler.fit_transform(df[df.columns])

# Display the first few rows of the cleaned and normalized dataset
df.head(), missing_values
STDOUT/STDERR
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
Cell In[1], line 1
----> 1 from sklearn.preprocessing import MinMaxScaler
      3 # Drop the 'name' column
      4 df = df.drop(columns=['name'])

ModuleNotFoundError: No module named 'sklearn'
[Jupyter current working directory: /workspace]
[Jupyter Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]
EXECUTE
%pip install scikit-learn
STDOUT/STDERR
Collecting scikit-learn
  Downloading scikit_learn-1.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)
Requirement already satisfied: numpy>=1.19.5 in /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages (from scikit-learn) (1.26.4)
Requirement already satisfied: scipy>=1.6.0 in /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages (from scikit-learn) (1.14.1)
Requirement already satisfied: joblib>=1.2.0 in /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages (from scikit-learn) (1.4.2)
Collecting threadpoolctl>=3.1.0 (from scikit-learn)
  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)
Downloading scikit_learn-1.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)
[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/12.9 MB ? eta -:--:--
[2K   ━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.5/12.9 MB 4.5 MB/s eta 0:00:03
[2K   ━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/12.9 MB 5.6 MB/s eta 0:00:02
[2K   ━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/12.9 MB 5.8 MB/s eta 0:00:02
[2K   ━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.2/12.9 MB 6.0 MB/s eta 0:00:02
[2K   ━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━ 5.5/12.9 MB 6.1 MB/s eta 0:00:02
[2K   ━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━ 6.8/12.9 MB 6.1 MB/s eta 0:00:02
[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━ 8.1/12.9 MB 6.1 MB/s eta 0:00:01
[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━ 9.4/12.9 MB 6.2 MB/s eta 0:00:01
[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━ 10.7/12.9 MB 6.2 MB/s eta 0:00:01
[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━ 11.8/12.9 MB 6.2 MB/s eta 0:00:01
[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.9/12.9 MB 6.2 MB/s eta 0:00:00
[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)
Installing collected packages: threadpoolctl, scikit-learn
Successfully installed scikit-learn-1.5.2 threadpoolctl-3.5.0

[notice] A new release of pip is available: 24.2 -> 24.3.1
[notice] To update, run: pip install --upgrade pip
Note: you may need to restart the kernel to use updated packages.
[Jupyter current working directory: /workspace]
[Jupyter Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]
EXECUTE
from sklearn.preprocessing import MinMaxScaler

# Drop the 'name' column
df = df.drop(columns=['name'])

# Check for missing values
missing_values = df.isnull().sum()

# Normalize the data using Min-Max scaling
scaler = MinMaxScaler()
df[df.columns] = scaler.fit_transform(df[df.columns])

# Display the first few rows of the cleaned and normalized dataset
df.head(), missing_values
STDOUT/STDERR
(   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \
 0     0.184308      0.112592      0.054815        0.195680          0.249012   
 1     0.198327      0.094930      0.278323        0.254130          0.288538   
 2     0.165039      0.059128      0.265288        0.280178          0.328063   
 3     0.165004      0.072927      0.264200        0.263342          0.328063   
 4     0.161150      0.080909      0.260107        0.354511          0.407115   
 
    MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \
 0  0.145472  0.247588    0.145288      0.312215          0.280197  ...   
 1  0.191233  0.323687    0.191042      0.472887          0.444536  ...   
 2  0.229287  0.369239    0.229411      0.390634          0.326212  ...   
 3  0.209056  0.324759    0.208862      0.414278          0.354971  ...   
 4  0.282755  0.437299    0.282870      0.499452          0.410025  ...   
 
    Shimmer:DDA       NHR       HNR  status      RPDE       DFA   spread1  \
 0     0.332584  0.068307  0.511745     1.0  0.369155  0.960148  0.569875   
 1     0.516048  0.059331  0.432577     1.0  0.470830  0.977024  0.703277   
 2     0.443317  0.039596  0.496220     1.0  0.404416  1.000000  0.636745   
 3     0.475478  0.040997  0.495936     1.0  0.416255  0.975885  0.695627   
 4     0.584542  0.054174  0.455499     1.0  0.375159  0.992813  0.762472   
 
     spread2        D2       PPE  
 0  0.585765  0.390661  0.497310  
 1  0.741337  0.473145  0.671326  
 2  0.686371  0.408819  0.596682  
 3  0.738089  0.436977  0.671949  
 4  0.513798  0.404336  0.757611  
 
 [5 rows x 23 columns],
 MDVP:Fo(Hz)         0
 MDVP:Fhi(Hz)        0
 MDVP:Flo(Hz)        0
 MDVP:Jitter(%)      0
 MDVP:Jitter(Abs)    0
 MDVP:RAP            0
 MDVP:PPQ            0
 Jitter:DDP          0
 MDVP:Shimmer        0
 MDVP:Shimmer(dB)    0
 Shimmer:APQ3        0
 Shimmer:APQ5        0
 MDVP:APQ            0
 Shimmer:DDA         0
 NHR                 0
 HNR                 0
 status              0
 RPDE                0
 DFA                 0
 spread1             0
 spread2             0
 D2                  0
 PPE                 0
 dtype: int64)
[Jupyter current working directory: /workspace]
[Jupyter Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]
EXECUTE
from sklearn.preprocessing import StandardScaler

# Separate features and target variable
X = df.drop(columns=['status'])
y = df['status']

# Standardize the features
scaler = StandardScaler()
X_standardized = scaler.fit_transform(X)

# Convert the standardized features back to a DataFrame
X_standardized_df = pd.DataFrame(X_standardized, columns=X.columns)

# Display the first few rows of the standardized features
X_standardized_df.head()
STDOUT/STDERR
   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \
0    -0.829300     -0.436165     -0.952037        0.334914          0.749759   
1    -0.770972     -0.530974     -0.057721        0.715418          1.037674   
2    -0.909476     -0.723168     -0.109875        0.884991          1.325589   
3    -0.909622     -0.649092     -0.114229        0.775389          1.325589   
4    -0.925657     -0.606245     -0.130608        1.368893          1.901418   

   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \
0  0.132963  0.760800    0.131755      0.745985          0.739536  ...   
1  0.453892  1.276809    0.452684      1.681731          1.768464  ...   
2  0.720770  1.585687    0.721813      1.202693          1.027636  ...   
3  0.578885  1.284076    0.577677      1.340396          1.207698  ...   
4  1.095750  2.047187    1.096793      1.836448          1.552389  ...   

   MDVP:APQ  Shimmer:DDA       NHR       HNR      RPDE       DFA   spread1  \
0  0.332985     0.607532 -0.067893 -0.193225 -0.807838  1.760814  0.801323   
1  1.159454     1.548254 -0.137843 -0.634508 -0.387524  1.837562  1.479853   
2  0.699187     1.175323 -0.291633 -0.279760 -0.662075  1.942048  1.141445   
3  0.806859     1.340229 -0.280719 -0.281346 -0.613134  1.832380  1.440945   
4  1.216839     1.899461 -0.178026 -0.506745 -0.783021  1.909364  1.780940   

    spread2        D2       PPE  
0  0.480477 -0.210531  0.868886  
1  1.311185  0.275077  1.803605  
2  1.017682 -0.103629  1.402661  
3  1.293840  0.062145  1.806954  
4  0.096195 -0.130026  2.267082  

[5 rows x 22 columns]
[Jupyter current working directory: /workspace]
[Jupyter Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]
EXECUTE
from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_standardized_df, y, test_size=0.2, random_state=42)

# Display the shapes of the training and testing sets
X_train.shape, X_test.shape, y_train.shape, y_test.shape
STDOUT/STDERR
((156, 22), (39, 22), (156,), (39,))
[Jupyter current working directory: /workspace]
[Jupyter Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]
EXECUTE
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import f1_score, make_scorer

# Define the logistic regression model
log_reg = LogisticRegression(penalty='l2', solver='liblinear')

# Define the parameter grid for cross-validation
param_grid = {'C': [0.01, 0.1, 1, 10, 100]}

# Define the F1 score as the scoring metric
f1_scorer = make_scorer(f1_score)

# Perform grid search with cross-validation
grid_search = GridSearchCV(log_reg, param_grid, scoring=f1_scorer, cv=5)
grid_search.fit(X_train, y_train)

# Get the best model and its parameters
best_log_reg = grid_search.best_estimator_
best_params = grid_search.best_params_

# Display the best parameters
best_params
STDOUT/STDERR
{'C': 10}
[Jupyter current working directory: /workspace]
[Jupyter Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]
EXECUTE
from sklearn.neighbors import KNeighborsClassifier

# Define the KNN model
knn = KNeighborsClassifier()

# Define the parameter grid for cross-validation
param_grid = {'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15]}

# Perform grid search with cross-validation
grid_search_knn = GridSearchCV(knn, param_grid, scoring=f1_scorer, cv=5)
grid_search_knn.fit(X_train, y_train)

# Get the best model and its parameters
best_knn = grid_search_knn.best_estimator_
best_params_knn = grid_search_knn.best_params_

# Display the best parameters
best_params_knn
STDOUT/STDERR
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast
  _data = np.array(data, dtype=dtype, copy=copy,
{'n_neighbors': 1}
[Jupyter current working directory: /workspace]
[Jupyter Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]
EXECUTE
from sklearn.neural_network import MLPClassifier

# Define the neural network model
mlp = MLPClassifier(max_iter=1000, random_state=42)

# Define the parameter grid for cross-validation
param_grid = {'hidden_layer_sizes': [(5,), (10,), (15,), (20,), (25,), (30,)]}

# Perform grid search with cross-validation
grid_search_mlp = GridSearchCV(mlp, param_grid, scoring=f1_scorer, cv=5)
grid_search_mlp.fit(X_train, y_train)

# Get the best model and its parameters
best_mlp = grid_search_mlp.best_estimator_
best_params_mlp = grid_search_mlp.best_params_

# Display the best parameters
best_params_mlp
STDOUT/STDERR
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
/openhands/poetry/openhands-ai-5O4_aCHf-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.
  warnings.warn(
{'hidden_layer_sizes': (10,)}
[Jupyter current working directory: /workspace]
[Jupyter Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]
EXECUTE
from sklearn.metrics import precision_score, recall_score, accuracy_score

# Function to evaluate a model
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    return precision, recall, f1, accuracy

# Evaluate the logistic regression model
log_reg_precision, log_reg_recall, log_reg_f1, log_reg_accuracy = evaluate_model(best_log_reg, X_test, y_test)

# Evaluate the KNN model
knn_precision, knn_recall, knn_f1, knn_accuracy = evaluate_model(best_knn, X_test, y_test)

# Evaluate the neural network model
mlp_precision, mlp_recall, mlp_f1, mlp_accuracy = evaluate_model(best_mlp, X_test, y_test)

# Display the results
{
    "Logistic Regression": {
        "Best Parameter": best_params,
        "Precision": log_reg_precision,
        "Recall": log_reg_recall,
        "F1 Score": log_reg_f1,
        "Accuracy": log_reg_accuracy
    },
    "KNN": {
        "Best Parameter": best_params_knn,
        "Precision": knn_precision,
        "Recall": knn_recall,
        "F1 Score": knn_f1,
        "Accuracy": knn_accuracy
    },
    "Neural Network": {
        "Best Parameter": best_params_mlp,
        "Precision": mlp_precision,
        "Recall": mlp_recall,
        "F1 Score": mlp_f1,
        "Accuracy": mlp_accuracy
    }
}
STDOUT/STDERR
{'Logistic Regression': {'Best Parameter': {'C': 10},
  'Precision': 0.9117647058823529,
  'Recall': 0.96875,
  'F1 Score': 0.9393939393939394,
  'Accuracy': 0.8974358974358975},
 'KNN': {'Best Parameter': {'n_neighbors': 1},
  'Precision': 1.0,
  'Recall': 0.96875,
  'F1 Score': 0.9841269841269841,
  'Accuracy': 0.9743589743589743},
 'Neural Network': {'Best Parameter': {'hidden_layer_sizes': (10,)},
  'Precision': 0.9393939393939394,
  'Recall': 0.96875,
  'F1 Score': 0.9538461538461539,
  'Accuracy': 0.9230769230769231}}
[Jupyter current working directory: /workspace]
[Jupyter Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]
EXECUTE
# Calculate the baseline performance
majority_class = y_train.mode()[0]
y_baseline = [majority_class] * len(y_test)

baseline_precision = precision_score(y_test, y_baseline)
baseline_recall = recall_score(y_test, y_baseline)
baseline_f1 = f1_score(y_test, y_baseline)
baseline_accuracy = accuracy_score(y_test, y_baseline)

# Display the baseline performance
{
    "Baseline": {
        "Precision": baseline_precision,
        "Recall": baseline_recall,
        "F1 Score": baseline_f1,
        "Accuracy": baseline_accuracy
    }
}
STDOUT/STDERR
{'Baseline': {'Precision': 0.8205128205128205,
  'Recall': 1.0,
  'F1 Score': 0.9014084507042254,
  'Accuracy': 0.8205128205128205}}
[Jupyter current working directory: /workspace]
[Jupyter Python interpreter: /openhands/poetry/openhands-ai-5O4_aCHf-py3.12/bin/python]